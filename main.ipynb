{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Description : AI Stuff. \n",
    "# Input: 2 videos of people dancing (1 student, 1 professional)\n",
    "# Output: \n",
    "    # 1. Score \n",
    "    # 2. Feedback \n",
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Machline Learning Model Imports\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Getting Data \n",
    "\n",
    "def make_directory(name : str):\n",
    "\n",
    "    # if the directory does NOT exist, create it\n",
    "    if not os.path.isdir(name):\n",
    "        os.mkdir(name)\n",
    "\n",
    "\n",
    "# Datatype -- int, float, string, bool\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def convertToMp4(path) -> str:\n",
    "\n",
    "    # funnyVideo.mov\n",
    "\n",
    "    _, extension = os.path.splitext(path)\n",
    "\n",
    "    if extension != '.mp4':\n",
    "        mp4_path = Path(path).stem + '.mp4' \n",
    "        clip = VideoFileClip(path)\n",
    "        clip.write_videofile(mp4_path, codec='libx264')\n",
    "\n",
    "        return mp4_path\n",
    "    \n",
    "\n",
    "    return path\n",
    "\n",
    "\n",
    "\n",
    "# Function -- get_frame_angles\n",
    "\n",
    "# Input: video_path : string\n",
    "# Output: For each frame in the video, we're going to output the angles \n",
    "# [\n",
    "\n",
    "    #Frame1,\n",
    "    # Frame2,\n",
    "    # Frame1000,\n",
    "\n",
    "# ]\n",
    "\n",
    "\n",
    "# student : tuple = (\"ShengLin\" , 4.0) \n",
    "\n",
    "\n",
    "\n",
    "# video_path = \"coolVideo.mp4\"\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "def get_frames_angles(video_path) -> tuple:\n",
    "\n",
    "\n",
    "    # main part of function is frames\n",
    "    frame_angles : list = []\n",
    "    \n",
    "    basename = os.path.basename(video_path)\n",
    "    image_name , _ = os.path.splitext(basename)\n",
    "\n",
    "    make_directory(image_name)\n",
    "\n",
    "\n",
    "    pose , poseDrawing = initializePoseTools()\n",
    "\n",
    "    \n",
    "    # frames = [\n",
    "        \n",
    "    #     [45.6, 78.1, 98.1],     # 1\n",
    "    #      [5.6, 34.1, 98.1],     # 2\n",
    "    #       [9.6, 78.1, 98.1],   \n",
    "    #        [45.6, 78.1, 98.1],                      \n",
    "    # ]\n",
    "\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    print(\"FPS: \" , fps)\n",
    "\n",
    "\n",
    "    img_count = 1\n",
    "\n",
    "    with pose.Pose(\n",
    "        min_detection_confidence = 0.5,\n",
    "        min_tracking_confidence = 0.5\n",
    "    ) as poseModel:\n",
    "        \n",
    "        while cap.isOpened():\n",
    "\n",
    "            success , frame = cap.read()\n",
    "\n",
    "            # Create an if statement that says: If it's not successful, then print out \"Could not read the frame\" \n",
    "\n",
    "            if not success:\n",
    "\n",
    "                print(\"Could not read the frame\")\n",
    "                break\n",
    "\n",
    "            \n",
    "\n",
    "            # If the program gets to here\n",
    "\n",
    "\n",
    "            # 1) Pose Process the Frame \n",
    "                # Annotate the image with the lines and circles on body parts\n",
    "                # Give us the Landmark Results -- we need this to get the angles\n",
    "            \n",
    "\n",
    "            # Put the pose model into our image\n",
    "            pose_processed_frame , landmark_results = pose_process_image(frame, poseModel)\n",
    "\n",
    "\n",
    "            image = draw_landmarks(landmark_results, poseDrawing, pose, pose_processed_frame)\n",
    "\n",
    "            # Test\n",
    "            # cv2.imshow(\"Frame\" , image)\n",
    "            # cv2.waitKey(1)\n",
    "\n",
    "            # 2) Get the Angles\n",
    "\n",
    "            h,w, _ = image.shape \n",
    "            \n",
    "            angles : list = get_angles_for_each_frame(pose, landmark_results, image, h, w)\n",
    "\n",
    "            # 3) Save the frame and save the angles\n",
    "\n",
    "            # frames = [\n",
    "        \n",
    "            #     [45.6, 78.1, 98.1],     # 1\n",
    "            #      [5.6, 34.1, 98.1],     # 2\n",
    "            #       [9.6, 78.1, 98.1],   \n",
    "            #        [45.6, 78.1, 98.1],                      \n",
    "            # ]\n",
    "\n",
    "            frame_angles.append(angles)\n",
    "\n",
    "                            #   golfVideo/1\n",
    "            imageFilePath = f\"{image_name}/{img_count}.jpg\"\n",
    "            img_count += 1\n",
    "\n",
    "            # At the path, save the image\n",
    "            cv2.imshow('Video' , image)\n",
    "            cv2.waitKey(1)\n",
    "            cv2.imwrite(imageFilePath, image)\n",
    "\n",
    "\n",
    "\n",
    "    return (frame_angles, image_name)\n",
    "\n",
    "\n",
    "import mediapipe as mp\n",
    "from mediapipe.python.solutions.pose import Pose\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def calculate_angle(a,b,c):\n",
    "    \n",
    "    # a = b = c = [x,y]\n",
    "\n",
    "    a = np.array(a) # p1\n",
    "    b = np.array(b) # p2\n",
    "    c = np.array(c) # p3\n",
    "\n",
    "\n",
    "    # USE arctan to calculate the angle\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0])   -    np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "\n",
    "    degrees = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    if degrees > 180.0:\n",
    "\n",
    "        degrees = 360 - degrees\n",
    "\n",
    "    return round(degrees,1)\n",
    "\n",
    "\n",
    "\n",
    "def draw_angle(actualCoordinate : tuple, image, angle):\n",
    "\n",
    "    \n",
    "\n",
    "    angleStr = str(angle)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontScale = 0.4\n",
    "    color = (255,255,255)\n",
    "    thickness = 1\n",
    "\n",
    "    \n",
    "    drawnImage = cv2.putText(image,angleStr, actualCoordinate,font,fontScale,color,thickness)\n",
    "\n",
    "    return drawnImage\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# function name : plot_angle\n",
    "# parameters : p1, p2, p3, landmark_results, image, h , w\n",
    "def plot_angle(p1,p2,p3,landmark_result,image,h ,w):\n",
    "\n",
    "    landmark_result = landmark_result.pose_landmarks.landmark\n",
    "    a = [   landmark_result[p1].x   ,   landmark_result[p1].y        ]\n",
    "\n",
    "    b = [     landmark_result[p2].x ,  landmark_result[p2].y   ]\n",
    "    c = [     landmark_result[p3].x ,   landmark_result[p2].y  ]\n",
    "\n",
    "    # Step 1 : Calculate the angle in degrees\n",
    "\n",
    "    angle = calculate_angle(a,b,c)\n",
    "\n",
    "    # angle = 134.6\n",
    "\n",
    "    # Step 2 : Draw the angle on the image\n",
    "\n",
    "    # the middle angle (b), angle calculation, image that we're gonna draw on\n",
    "\n",
    "\n",
    "    actualXCoordinate = int(b[0] * w)\n",
    "    actualYCoordinate = int(b[1] * h)\n",
    "\n",
    "    actualCoordinate = tuple(np.multiply(b,[w,h]).astype(int))\n",
    "\n",
    "\n",
    "    actualCoordinate = (actualXCoordinate,actualYCoordinate)\n",
    "\n",
    "\n",
    "    drawnImage = draw_angle(actualCoordinate, image, angle)\n",
    "    \n",
    "    return angle, drawnImage\n",
    "\n",
    "\n",
    "\n",
    "def get_angles_for_each_frame(mp_pose, landmarks, image, h, w):\n",
    "    \n",
    "    # 6 angles\n",
    "    angles = []\n",
    "    val = 50\n",
    "\n",
    "    # 3 points\n",
    "        # 1. Left Shoulder\n",
    "        # 2. Left Elbow\n",
    "        # 3. Left Wrist\n",
    "    \n",
    "    angle, image = plot_angle(mp_pose.PoseLandmark.LEFT_SHOULDER.value,\n",
    "                              mp_pose.PoseLandmark.LEFT_ELBOW.value,\n",
    "                              mp_pose.PoseLandmark.LEFT_WRIST.value, landmarks, image, h, w + val)\n",
    "    angles.append(angle)\n",
    "    angle, image = plot_angle(mp_pose.PoseLandmark.RIGHT_SHOULDER.value,\n",
    "                              mp_pose.PoseLandmark.RIGHT_ELBOW.value,\n",
    "                              mp_pose.PoseLandmark.RIGHT_WRIST.value, landmarks, image, h, w - val)\n",
    "    angles.append(angle)\n",
    "    angle, image = plot_angle(mp_pose.PoseLandmark.LEFT_HIP.value,\n",
    "                              mp_pose.PoseLandmark.LEFT_KNEE.value,\n",
    "                              mp_pose.PoseLandmark.LEFT_ANKLE.value, landmarks, image, h, w + val)\n",
    "    angles.append(angle)\n",
    "    angle, image = plot_angle(mp_pose.PoseLandmark.RIGHT_HIP.value,\n",
    "                              mp_pose.PoseLandmark.RIGHT_KNEE.value,\n",
    "                              mp_pose.PoseLandmark.RIGHT_ANKLE.value, landmarks, image, h, w - val)\n",
    "    angles.append(angle)\n",
    "\n",
    "\n",
    "\n",
    "    angle, image = plot_angle(mp_pose.PoseLandmark.LEFT_SHOULDER.value,\n",
    "                              mp_pose.PoseLandmark.LEFT_HIP.value,\n",
    "                              mp_pose.PoseLandmark.LEFT_KNEE.value, landmarks, image, h, w + val)\n",
    "    angles.append(angle)\n",
    "\n",
    "\n",
    "\n",
    "    angle, image = plot_angle(mp_pose.PoseLandmark.RIGHT_SHOULDER.value,\n",
    "                              mp_pose.PoseLandmark.RIGHT_HIP.value,\n",
    "                              mp_pose.PoseLandmark.RIGHT_KNEE.value, landmarks, image, h, w - val)\n",
    "    angles.append(angle)\n",
    "\n",
    "\n",
    "\n",
    "    angle, image = plot_angle(mp_pose.PoseLandmark.LEFT_WRIST.value,\n",
    "                             mp_pose.PoseLandmark.LEFT_SHOULDER.value,\n",
    "                             mp_pose.PoseLandmark.LEFT_HIP.value, landmarks, image, h, w + val)\n",
    "    angles.append(angle)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    angle_wrist_shoulder_hip_right, image = plot_angle(mp_pose.PoseLandmark.RIGHT_WRIST.value,\n",
    "                                                       mp_pose.PoseLandmark.RIGHT_SHOULDER.value,\n",
    "                                                       mp_pose.PoseLandmark.RIGHT_HIP.value, landmarks, image, h,\n",
    "                                                       w - val)\n",
    "    \n",
    "    angles.append(angle_wrist_shoulder_hip_right)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # cv2.imshow('Hopefully this works' , image)\n",
    "    # cv2.waitKey(1)\n",
    "\n",
    "    return angles\n",
    "\n",
    "def draw_landmarks(results, mp_drawing, mp_pose, image):\n",
    "    # for idx (index), x (value) in enumerate(_____):   \\\\storing both the index and the value\n",
    "    # work w/both variables simultaneously; requires\n",
    "    for idx, landmark in enumerate(results.pose_landmarks.landmark):\n",
    "        # we care about 11-16 and 23-28\n",
    "        if idx in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 17, 18, 19, 20, 21, 22, 29, 30, 31, 32]:\n",
    "            results.pose_landmarks.landmark[idx].visibility = 0  # remove visibility of specific landmarks\n",
    "\n",
    "    # draw landmarks\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2),\n",
    "                              # customize color, etc\n",
    "                              mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def initializePoseTools():\n",
    "\n",
    "    pose = mp.solutions.pose\n",
    "    \n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "\n",
    "    return pose, mp_drawing\n",
    "\n",
    "def pose_process_image(openCVFrame, poseModel : Pose ) -> tuple:\n",
    "    \n",
    "    \n",
    "    # OpenCV processes images in BGR\n",
    "\n",
    "    # Mediapipe processes images in RGB\n",
    "    \n",
    "\n",
    "    # RGB <------  BGR\n",
    "    rgbImage = cv2.cvtColor(openCVFrame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Since it's in mediapipe image format now, we can use the pose model\n",
    "\n",
    "\n",
    "\n",
    "    # After this line, rgbImage now has the lines and marks\n",
    "    landmark_results = poseModel.process(rgbImage)\n",
    "    \n",
    "    # if landmark_results.pose_landmarks:\n",
    "\n",
    "    #     for id, landmark in enumerate(landmark_results.pose_landmarks.landmark):\n",
    "\n",
    "    #         print(id)\n",
    "    #         print(f\"x: {landmark.x}\")\n",
    "    #         print(f\"y: {landmark.y}\")\n",
    "    #         print(f\"z: {landmark.z}\")\n",
    "\n",
    "    #         print()\n",
    "    \n",
    "    \n",
    "    # BGR  <-------- RGB\n",
    "    openCVFrame = cv2.cvtColor(rgbImage , cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    return (openCVFrame, landmark_results)\n",
    "\n",
    "    # .mov, mp4 -- video extensions\n",
    "    # .pdf .txt -- text extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 3) Using Machine Learning\n",
    "\n",
    "\n",
    "def euclidean_distance(p1, p2):\n",
    "    if len(p1) != len(p2):\n",
    "        raise ValueError(\"Lists must have the same number of elements\")\n",
    "    \n",
    "    squared_diff_sum = sum((x - y) ** 2 for x, y in zip(p1, p2))\n",
    "    distance = math.sqrt(squared_diff_sum)\n",
    "    return distance\n",
    "\n",
    "def get_image_urls(studentVideoFrameData, professionalVideoFrameData, studentFolderName, professsionalFolderName, studentVideoKeyFrames : list, professionalVideoKeyFrames : list):\n",
    "    \n",
    "\n",
    "    # 1) Use the Student Data (video1FrameData) and create the clusters\n",
    "\n",
    "    student_cluster = get_cluster(studentVideoFrameData)\n",
    "\n",
    "    # 2) Create 2 groups of clusters and compare\n",
    "\n",
    "    public_urls = []\n",
    "\n",
    "    for label in student_cluster:\n",
    "        \n",
    "        \n",
    "        index_student = (label['start'] + label['end']) // 2\n",
    "\n",
    "        student_image = f\"{studentFolderName}/{index_student}.jpg\"\n",
    "        \n",
    "\n",
    "        smallestDistance = float('inf')\n",
    "        index_professional = 0  # TODO: change to distance formula next week\n",
    "\n",
    "        i = 0\n",
    "        for eachProfessionalFrame in professionalVideoFrameData:\n",
    "            studentFrame = studentVideoFrameData[index_student]\n",
    "            # print(studentFrame)\n",
    "            # print(eachProfessionalFrame)\n",
    "\n",
    "            currDistance = euclidean_distance(studentFrame,eachProfessionalFrame)\n",
    "\n",
    "            if currDistance < smallestDistance:\n",
    "                index_professional = i\n",
    "                smallestDistance = currDistance\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        \n",
    "\n",
    "        professional_image =  f\"{professsionalFolderName}/{index_professional}.jpg\"\n",
    "\n",
    "\n",
    "        # TODO: Set up the database\n",
    "\n",
    "\n",
    "        # TODO: Send student and professional images to database\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # update key frames to compare\n",
    "\n",
    "        studentVideoKeyFrames.append(studentVideoFrameData[index_student])\n",
    "        professionalVideoKeyFrames.append(professionalVideoFrameData[index_professional])\n",
    "\n",
    "\n",
    "    return public_urls\n",
    "\n",
    "\n",
    "\n",
    "def get_cluster(video1FrameData):\n",
    "    \n",
    "    # Figure out how many there are\n",
    "\n",
    "    numClusters = kmean_hyper_param_tuning(video1FrameData)\n",
    "\n",
    "    X = np.array(video1FrameData)\n",
    "\n",
    "    # Create KMeans model (best line of fit) with 'n' clusters using our video1 data\n",
    "    kmeans_1 = KMeans(n_clusters=numClusters).fit(X)\n",
    "\n",
    "    student_cluster = []\n",
    "\n",
    "    start = 0\n",
    "             \n",
    "    labels = kmeans_1.labels_\n",
    "    \n",
    "    for i in range(1,len(labels)):\n",
    "\n",
    "        if labels[i] != labels[i-1]:\n",
    "            student_cluster.append(\n",
    "                {\n",
    "                    'start' : start,\n",
    "                    'end' : i - 1,\n",
    "                    'label' : labels[i-1]\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    else:\n",
    "\n",
    "        # last cluster\n",
    "\n",
    "        student_cluster.append(\n",
    "                {\n",
    "                    'start' : start,\n",
    "                    'end' : i,\n",
    "                    'label' : labels[i]\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    return student_cluster\n",
    "\n",
    "\n",
    "# The NUMBER of key frames\n",
    "\n",
    "# n_clusters - how many stages (pictures) there will be\n",
    "\n",
    "# purpose: determine how many pictures\n",
    "\n",
    "def kmean_hyper_param_tuning(video1FrameData):\n",
    "    \n",
    "    parameters = []\n",
    "\n",
    "\n",
    "    for i in range(2,31):\n",
    "        parameters.append(i)\n",
    "\n",
    "    parameter_grid = ParameterGrid({'n_clusters' : parameters})\n",
    "    \n",
    "    # go through params in parameter_grid (check which one is the best)\n",
    "    \n",
    "    best_score = -1\n",
    "    best_grid  = {}\n",
    "\n",
    "    kmeans_model = KMeans()\n",
    "\n",
    "    for p in parameter_grid:\n",
    "\n",
    "        kmeans_model.set_params(**p)\n",
    "        kmeans_model.fit(video1FrameData)\n",
    "\n",
    "        ss = metrics.silhouette_score(video1FrameData, kmeans_model.labels_)\n",
    "\n",
    "        # print(\"Parameter:\", p, 'Score:', ss)\n",
    "\n",
    "        if ss > best_score:\n",
    "            best_score = ss\n",
    "            best_grid = p\n",
    "\n",
    "    return best_grid['n_clusters']\n",
    "\n",
    "\n",
    "def analyze_dance_quality(average_error):\n",
    "    if 0 <= average_error <= 5:\n",
    "        return \"Outstanding! Your dance performance is exceptional. Consider experimenting with complex choreography \" \\\n",
    "               \"and unique movements to further elevate your skills. \"\n",
    "    elif 5 < average_error <= 10:\n",
    "        return \"Excellent Dance Performance. Your technique is nearly flawless. Try incorporating more expression \" \\\n",
    "               \"and emotion into your movements for an even more captivating performance. \"\n",
    "    elif 10 < average_error <= 15:\n",
    "        return \"Very Impressive! Your dance quality is excellent with only minor imperfections. Focus on refining \" \\\n",
    "               \"transitions and adding your personal touch to make your performance truly memorable. \"\n",
    "    elif 15 < average_error <= 20:\n",
    "        return \"Great Job! Your dance performance is strong. Work on perfecting specific poses and movements to \" \\\n",
    "               \"enhance overall fluidity and grace. \"\n",
    "    elif 20 < average_error <= 30:\n",
    "        return \"Good Dance Performance. You're doing well, but there's room for improvement. Pay attention to details \" \\\n",
    "               \"and explore variations in your dance routine to keep it engaging. \"\n",
    "    elif 30 < average_error <= 40:\n",
    "        return \"Competent Dance Performance. Your dance quality is solid, but there are noticeable areas for \" \\\n",
    "               \"improvement. Practice specific movements and experiment with different styles to broaden your \" \\\n",
    "               \"repertoire. \"\n",
    "    elif 40 < average_error <= 50:\n",
    "        return \"Fair Dance Performance. Your dance skills are average. Focus on mastering fundamental techniques, \" \\\n",
    "               \"improving coordination, and maintaining good posture throughout your routine. \"\n",
    "    elif 50 < average_error <= 60:\n",
    "        return \"Needs Improvement. Significant improvement is required in various aspects of your dance performance. \" \\\n",
    "               \"Consider seeking guidance from a dance instructor and dedicating more time to practice. \"\n",
    "    elif 60 < average_error <= 70:\n",
    "        return \"Below Average. Your dance quality needs substantial improvement. Work on foundational movements, \" \\\n",
    "               \"posture, and timing. Regular practice and feedback from an instructor can make a significant \" \\\n",
    "               \"difference. \"\n",
    "    elif 70 < average_error <= 80:\n",
    "        return \"Poor Dance Quality. Your performance is below expectations. Revisit basic dance principles, \" \\\n",
    "               \"refine coordination, and seek personalized coaching to address specific weaknesses. \"\n",
    "    elif 80 < average_error <= 90:\n",
    "        return \"Very Low Dance Quality. Your dance skills are significantly below the desired standard. Consider \" \\\n",
    "               \"starting with the basics, focusing on rhythm, and seeking intensive training to build a strong \" \\\n",
    "               \"foundation. \"\n",
    "    elif 90 < average_error <= 100:\n",
    "        return \"Extremely Low Dance Quality. Substantial improvement is needed in every aspect of your dance \" \\\n",
    "               \"performance. Consider enrolling in beginner dance classes to develop fundamental skills and \" \\\n",
    "               \"techniques. \"\n",
    "    else:\n",
    "        return \"Invalid score. Please provide a score within the valid range (0-100).\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_videos_to_mp4(videoPath1: str, videoPath2: str):\n",
    "    print(\"Converting Videos to MP4\")\n",
    "    videoPath1 = convertToMp4(videoPath1)\n",
    "    videoPath2 = convertToMp4(videoPath2)\n",
    "    return videoPath1, videoPath2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frame_angles(videoPath: str):\n",
    "    print(\"Extracting Frame Angles\")\n",
    "    frameData, imageName = get_frames_angles(videoPath)\n",
    "    return frameData, imageName\n",
    "\n",
    "def get_frame_data(videoPath1: str, videoPath2: str):\n",
    "    video1FrameData, imageName1 = extract_frame_angles(videoPath1)\n",
    "    video2FrameData, imageName2 = extract_frame_angles(videoPath2)\n",
    "    return video1FrameData, video2FrameData, imageName1, imageName2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_machine_learning(video1FrameData, video2FrameData, imageName1: str, imageName2: str):\n",
    "    print(\"Processing Machine Learning\")\n",
    "    video1KeyFrames = []\n",
    "    video2KeyFrames = []\n",
    "    public_urls = get_image_urls(video1FrameData, video2FrameData, imageName1, imageName2, video1KeyFrames, video2KeyFrames)\n",
    "    return public_urls, video1KeyFrames, video2KeyFrames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Videos to MP4\n"
     ]
    }
   ],
   "source": [
    "videoPath1 , videoPath2 = convert_videos_to_mp4(\"videos/golfVideo.mp4\", \"videos/golfVideo.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Frame Angles\n",
      "FPS:  30.306443190777014\n",
      "Could not read the frame\n",
      "Extracting Frame Angles\n",
      "FPS:  30.306443190777014\n",
      "Could not read the frame\n"
     ]
    }
   ],
   "source": [
    "video1FrameData, video2FrameData, imageName1, imageName2 = get_frame_data(videoPath1, videoPath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Machine Learning\n"
     ]
    }
   ],
   "source": [
    "public_urls, video1KeyFrames, video2KeyFrames = process_machine_learning(video1FrameData, video2FrameData, imageName1, imageName2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# # Functions \n",
    "\n",
    "\n",
    "\n",
    "# # This is the main function\n",
    "\n",
    "\n",
    "# def process_videos(videoPath1 : str , videoPath2 : str):\n",
    "\n",
    "#     print(\"Processing Videos\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     # 1) TO MP4\n",
    "\n",
    "#     # We want the video to be .mp4\n",
    "\n",
    "#     videoPath1 = convertToMp4(videoPath1)\n",
    "#     videoPath2 = convertToMp4(videoPath2)\n",
    "\n",
    "    \n",
    "    \n",
    "#     # We want to get the \"Frame Angles\"\n",
    "#         # Frame Angles -- Array of different angles in the body (btwn shoulder elbow wrist)\n",
    "\n",
    "\n",
    "#     # 2) Getting our data\n",
    "\n",
    "#     video1FrameData , imageName1 = get_frames_angles(videoPath1)\n",
    "#     video2FrameData , imageName2 = get_frames_angles(videoPath2)\n",
    "\n",
    "\n",
    "#     # 3) Using Machine Learning\n",
    "\n",
    "    \n",
    "#     video1KeyFrames = []\n",
    "#     video2KeyFrames = []\n",
    "#                                                                 #  golfVideo   golfVideo2\n",
    "#     public_urls = get_image_urls(video1FrameData, video2FrameData, imageName1, imageName2, video1KeyFrames, video2KeyFrames)\n",
    "\n",
    "\n",
    "#     # TODO: Average Error and Suggestions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# process_videos(\"golfVideo.mp4\" , \"golfVideo.mp4\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DanceBackendEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
